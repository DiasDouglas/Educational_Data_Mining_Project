---
title: "How the Coronavirus Changed People's Thoughts About Education? An Analysis Using Keywords on Twitter"
author: "Douglas Dias, Carlos Azevedo - Department of Computing, UFRPE"
date: "14/09/2020"
output: html_document
---

```{r setup, include=FALSE}
#Instalar
install.packages("tm", repos = 'http://cran.us.r-project.org')
install.packages("wordcloud", repos = 'http://cran.us.r-project.org')
install.packages("RColorBrewer", repos = 'http://cran.us.r-project.org')
install.packages("twitteR", repos = 'http://cran.us.r-project.org')
install.packages("syuzhet", repos = 'http://cran.us.r-project.org')

#Carregar
library("tm")
library("wordcloud")
library("RColorBrewer")
library("twitteR")
library("syuzhet")

config <- read.csv("config_twitter.csv", header = T, sep = ';')

consumer_key <- config$API_KEY
consumer_secret <- config$API_SECRET_KEY
access_token <- config$ACCESS_TOKEN
access_secret <- config$ACCESS_TOKEN_SECRET

setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)

```

<center>

This paper was developed as a final project for the Educational Data Mining class, lectured by Dr. Rafael Mello.

</center>

# {.tabset}

## Introduction

The objective of this paper is to collect, process and analyze data from the last year, by month, about some keywords, related to education, on Twitter. After that, we will compare the related topics before and after the COVID-19 spread throught the world. The results will be used to learn what has changed, what are de difficulties and the new characteristics related to education. The focus of this work will be on english tweets. 

```{r include=FALSE}
tweets <- searchTwitter("Covid", n=1000, lang="en", since='2020-10-15', until='2020-10-19')
# Converts all tweets to the Data Frame format.
tweets <- twListToDF(tweets)

# Collapsing all tweets into a unidimensional vector
tweets_t <- paste(tweets$text, collapse = " ")

tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)

# To lowercase
corpus <- tm_map(corpus, tolower)
# Removes punctuation
corpus <- tm_map(corpus, removePunctuation)
# Removes whitespaces
corpus <- tm_map(corpus, stripWhitespace)
# Removes stopwords
corpus <- tm_map(corpus, removeWords, stopwords("en"))
# Removes URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus <- tm_map(corpus, removeURL)
# Removes anything that is not english letters or whitespaces.
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))

dtm <- TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)

fre <- sort(rowSums(dtm),decreasing=TRUE)

```

```{r}
wordcloud(corpus, min.freq = 1, max.words=100,
          random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```

## Data Extraction {.tabset}

Each one of the following tabs represents one keyword, searched on Twitter.

### Education {.tabset}

#### Word Cloud 

```{r include=FALSE}
tweets <- searchTwitter("Education", n=1000, lang="en")
# Converts all tweets to the Data Frame format.
tweets <- twListToDF(tweets)

# Collapsing all tweets into a unidimensional vector
tweets_t <- paste(tweets$text, collapse = " ")

tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)

# To lowercase
corpus <- tm_map(corpus, tolower)
# Removes punctuation
corpus <- tm_map(corpus, removePunctuation)
# Removes whitespaces
corpus <- tm_map(corpus, stripWhitespace)
# Removes stopwords
corpus <- tm_map(corpus, removeWords, stopwords("en"))
# Removes URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus <- tm_map(corpus, removeURL)
# Removes anything that is not english letters or whitespaces.
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))

dtm <- TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)

fre <- sort(rowSums(dtm),decreasing=TRUE)

```

```{r}
wordcloud(corpus, min.freq = 1, max.words=100,
          random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```


#### Sentiment Analysis

```{r include=FALSE}
  # Gives points to the tweets, measuring them
  tweets_texts <- tweets$text
  s <- get_nrc_sentiment(tweets_texts)
```

```{r}
  barplot(colSums(s), las=2, col = rainbow(10),
    ylab = "Quantity", main = "Sentiment Score for 'Education'")
```

### Learning Analytics {.tabset}

#### Word Cloud 

```{r include=FALSE}
tweets <- searchTwitter("Learning+Analytics", n=1000, lang="en")
# Converts all tweets to the Data Frame format.
tweets <- twListToDF(tweets)

# Collapsing all tweets into a unidimensional vector
tweets_t <- paste(tweets$text, collapse = " ")

tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)

# To lowercase
corpus <- tm_map(corpus, tolower)
# Removes punctuation
corpus <- tm_map(corpus, removePunctuation)
#Removes extras whitespaces
corpus <- tm_map(corpus, stripWhitespace)
# Removes stopwords
corpus <- tm_map(corpus, removeWords, stopwords("en"))
# Removes URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus <- tm_map(corpus, removeURL)
# Removes anything that is not english letters or whitespaces
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))

dtm <- TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)

fre <- sort(rowSums(dtm),decreasing=TRUE)

```

```{r }
wordcloud(corpus, min.freq = 1, max.words=100,
          random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```


#### Sentiment Analysis

```{r include=FALSE}
  # Gives points to the tweets, measuring them
  tweets_texts <- tweets$text
  s <- get_nrc_sentiment(tweets_texts)
```

```{r }
  barplot(colSums(s), las=2, col = rainbow(10),
    ylab = "Quantity", main = "Sentiment Score for 'LearningAnalytics'")
```

### Educational Data Mining {.tabset}

#### Word Cloud 

```{r include=FALSE}
tweets <- searchTwitter("Educational+Data+Mining", n=1000, lang="en")
# Converts all tweets to the Data Frame format.
tweets <- twListToDF(tweets)

# Collapsing all tweets into a unidimensional vector
tweets_t <- paste(tweets$text, collapse = " ")

tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)

# To lowercase
corpus <- tm_map(corpus, tolower)
# Removes punctuation
corpus <- tm_map(corpus, removePunctuation)
#Removes extras whitespaces
corpus <- tm_map(corpus, stripWhitespace)
# Removes stopwords
corpus <- tm_map(corpus, removeWords, stopwords("en"))
# Removes URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus <- tm_map(corpus, removeURL)
# Removes anything that is not english letters or whitespaces
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))

dtm <- TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)

fre <- sort(rowSums(dtm),decreasing=TRUE)

```

```{r }
wordcloud(corpus, min.freq = 1, max.words=100,
          random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```


#### Sentiment Analysis

```{r include=FALSE}
  # Gives points to the tweets, measuring them
  tweets_texts <- tweets$text
  s <- get_nrc_sentiment(tweets_texts)
```

```{r }
  barplot(colSums(s), las=2, col = rainbow(10),
    ylab = "Quantity", main = "Sentiment Score for 'Educational Data Mining'")
```

### Students {.tabset}

#### Word Cloud 

```{r include=FALSE}
tweets <- searchTwitter("Students", n=1000, lang="en")
# Converts all tweets to the Data Frame format.
tweets <- twListToDF(tweets)

# Collapsing all tweets into a unidimensional vector
tweets_t <- paste(tweets$text, collapse = " ")

tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)

# To lowercase
corpus <- tm_map(corpus, tolower)
# Removes punctuation
corpus <- tm_map(corpus, removePunctuation)
#Removes extras whitespaces
corpus <- tm_map(corpus, stripWhitespace)
# Removes stopwords
corpus <- tm_map(corpus, removeWords, stopwords("en"))
# Removes URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus <- tm_map(corpus, removeURL)
# Removes anything that is not english letters or whitespaces
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))

dtm <- TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)

fre <- sort(rowSums(dtm),decreasing=TRUE)

```

```{r }
wordcloud(corpus, min.freq = 1, max.words=100,
          random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```


#### Sentiment Analysis

```{r include=FALSE}
  # Gives points to the tweets, measuring them
  tweets_texts <- tweets$text
  s <- get_nrc_sentiment(tweets_texts)
```

```{r }
  barplot(colSums(s), las=2, col = rainbow(10),
    ylab = "Quantity", main = "Sentiment Score for 'Students'")
```

### Schools {.tabset}

#### Word Cloud 

```{r include=FALSE}
tweets <- searchTwitter("Schools", n=1000, lang="en")
# Converts all tweets to the Data Frame format.
tweets <- twListToDF(tweets)

# Collapsing all tweets into a unidimensional vector
tweets_t <- paste(tweets$text, collapse = " ")

tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)

# To lowercase
corpus <- tm_map(corpus, tolower)
# Removes punctuation
corpus <- tm_map(corpus, removePunctuation)
#Removes extras whitespaces
corpus <- tm_map(corpus, stripWhitespace)
# Removes stopwords
corpus <- tm_map(corpus, removeWords, stopwords("en"))
# Removes URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus <- tm_map(corpus, removeURL)
# Removes anything that is not english letters or whitespaces
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))

dtm <- TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)

fre <- sort(rowSums(dtm),decreasing=TRUE)

```

```{r }
wordcloud(corpus, min.freq = 1, max.words=100,
          random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```


#### Sentiment Analysis

```{r include=FALSE}
  # Gives points to the tweets, measuring them
  tweets_texts <- tweets$text
  s <- get_nrc_sentiment(tweets_texts)
```

```{r }
  barplot(colSums(s), las=2, col = rainbow(10),
    ylab = "Quantity", main = "Sentiment Score for 'Schools'")
```

### Pandemic Education {.tabset}

#### Word Cloud 

```{r include=FALSE}
tweets <- searchTwitter("Pandemic+Education", n=1000, lang="en")
# Converts all tweets to the Data Frame format.
tweets <- twListToDF(tweets)

# Collapsing all tweets into a unidimensional vector
tweets_t <- paste(tweets$text, collapse = " ")

tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)

# To lowercase
corpus <- tm_map(corpus, tolower)
# Removes punctuation
corpus <- tm_map(corpus, removePunctuation)
#Removes extras whitespaces
corpus <- tm_map(corpus, stripWhitespace)
# Removes stopwords
corpus <- tm_map(corpus, removeWords, stopwords("en"))
# Removes URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus <- tm_map(corpus, removeURL)
# Removes anything that is not english letters or whitespaces
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))

dtm <- TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)

fre <- sort(rowSums(dtm),decreasing=TRUE)

```

```{r }
wordcloud(corpus, min.freq = 1, max.words=100,
          random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```


#### Sentiment Analysis

```{r include=FALSE}
  # Gives points to the tweets, measuring them
  tweets_texts <- tweets$text
  s <- get_nrc_sentiment(tweets_texts)
```

```{r }
  barplot(colSums(s), las=2, col = rainbow(10),
    ylab = "Quantity", main = "Sentiment Score for 'Pandemic Education'")
```

### E-Learning {.tabset}

#### Word Cloud 

```{r include=FALSE}
tweets <- searchTwitter("E-Learning", n=1000, lang="en")
# Converts all tweets to the Data Frame format.
tweets <- twListToDF(tweets)

# Collapsing all tweets into a unidimensional vector
tweets_t <- paste(tweets$text, collapse = " ")

tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)

# To lowercase
corpus <- tm_map(corpus, tolower)
# Removes punctuation
corpus <- tm_map(corpus, removePunctuation)
#Removes extras whitespaces
corpus <- tm_map(corpus, stripWhitespace)
# Removes stopwords
corpus <- tm_map(corpus, removeWords, stopwords("en"))
# Removes URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus <- tm_map(corpus, removeURL)
# Removes anything that is not english letters or whitespaces
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))

dtm <- TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)

fre <- sort(rowSums(dtm),decreasing=TRUE)

```

```{r }
wordcloud(corpus, min.freq = 1, max.words=100,
          random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```


#### Sentiment Analysis

```{r include=FALSE}
  # Gives points to the tweets, measuring them
  tweets_texts <- tweets$text
  s <- get_nrc_sentiment(tweets_texts)
```

```{r }
  barplot(colSums(s), las=2, col = rainbow(10),
    ylab = "Quantity", main = "Sentiment Score for 'E-Learning'")
```

### Homeschooling {.tabset}

#### Word Cloud 

```{r include=FALSE}
tweets <- searchTwitter("Homeschooling", n=1000, lang="en")
# Converts all tweets to the Data Frame format.
tweets <- twListToDF(tweets)

# Collapsing all tweets into a unidimensional vector
tweets_t <- paste(tweets$text, collapse = " ")

tweets_S <- VectorSource(tweets_t)
corpus <- Corpus(tweets_S)

# To lowercase
corpus <- tm_map(corpus, tolower)
# Removes punctuation
corpus <- tm_map(corpus, removePunctuation)
#Removes extras whitespaces
corpus <- tm_map(corpus, stripWhitespace)
# Removes stopwords
corpus <- tm_map(corpus, removeWords, stopwords("en"))
# Removes URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus <- tm_map(corpus, removeURL)
# Removes anything that is not english letters or whitespaces
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))

dtm <- TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)

fre <- sort(rowSums(dtm),decreasing=TRUE)

```

```{r }
wordcloud(corpus, min.freq = 1, max.words=100,
          random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```


#### Sentiment Analysis

```{r include=FALSE}
  # Gives points to the tweets, measuring them
  tweets_texts <- tweets$text
  s <- get_nrc_sentiment(tweets_texts)
```

```{r }
  barplot(colSums(s), las=2, col = rainbow(10),
    ylab = "Quantity", main = "Sentiment Score for 'Homeschooling'")
```




## Data Analysis

## Conclusions